"""
CliCare - Chatbot Performance Testing (50 Test Cases)
python test3_chatbot_50cases.py
"""

import requests
import pandas as pd
import numpy as np
import json
import time
from datetime import datetime, timedelta
import os

# ============================================================================
# CONFIGURATION
# ============================================================================

API_BASE = "http://localhost:5000"
OUTPUT_DIR = "chatbot_test_results/performance"

# ‚ö†Ô∏è AGGRESSIVE RATE LIMITING CONFIGURATION
DELAY_BETWEEN_REQUESTS = 8  # seconds (7.5 requests per minute - SAFE)
MAX_REQUESTS_PER_MINUTE = 7  # Conservative limit (Gemini free tier: 15 RPM)
RETRY_ATTEMPTS = 3
EXPONENTIAL_BACKOFF_BASE = 45  # Start with 45s wait on rate limit

# Test credentials
TEST_ADMIN = {
    "healthadminid": "ADMIN001",
    "password": "admin123"
}

# Track requests for rate limiting
request_log = []

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def create_output_dir():
    """Create output directory"""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    print(f"üìÅ Output directory: {OUTPUT_DIR}")

def print_header(title):
    """Print section header"""
    print("\n" + "="*80)
    print(title.center(80))
    print("="*80 + "\n")

def smart_rate_limit():
    """
    AGGRESSIVE rate limiting with multiple safety layers
    Prevents Gemini API quota exhaustion
    """
    global request_log
    
    now = datetime.now()
    
    # Remove requests older than 1 minute
    one_minute_ago = now - timedelta(minutes=1)
    request_log = [ts for ts in request_log if ts > one_minute_ago]
    
    # Check if we hit the limit
    if len(request_log) >= MAX_REQUESTS_PER_MINUTE:
        oldest = min(request_log)
        wait_time = 60 - (now - oldest).total_seconds()
        
        if wait_time > 0:
            print(f"‚è≥ Rate limit protection: Waiting {wait_time:.1f}s...", end=' ', flush=True)
            time.sleep(wait_time + 2)  # +2s safety buffer
            print("‚úì")
            request_log.clear()
    
    # Add current request timestamp
    request_log.append(now)
    
    # Mandatory delay between ALL requests
    print(f"‚è±Ô∏è  Rate limit delay: {DELAY_BETWEEN_REQUESTS}s...", end=' ', flush=True)
    time.sleep(DELAY_BETWEEN_REQUESTS)
    print("‚úì")

def make_request(endpoint, method="GET", data=None, headers=None, retry_count=0):
    """
    Make API request with rate limiting and retry logic
    """
    try:
        url = f"{API_BASE}/{endpoint}"
        
        if method == "GET":
            response = requests.get(url, headers=headers, timeout=45)
        elif method == "POST":
            response = requests.post(url, json=data, headers=headers, timeout=45)
        
        # Handle rate limit (429)
        if response.status_code == 429:
            if retry_count < RETRY_ATTEMPTS:
                wait_time = EXPONENTIAL_BACKOFF_BASE * (2 ** retry_count)
                print(f"\nüö® Rate limit! Waiting {wait_time}s (Attempt {retry_count + 1}/{RETRY_ATTEMPTS})")
                time.sleep(wait_time)
                return make_request(endpoint, method, data, headers, retry_count + 1)
            else:
                print(f"\n‚ùå Rate limit exceeded after {RETRY_ATTEMPTS} attempts")
                return None
        
        # Handle 503 (Service Unavailable)
        if response.status_code == 503:
            if retry_count < RETRY_ATTEMPTS:
                wait_time = 10 * (retry_count + 1)  # 10s, 20s, 30s
                print(f"\n‚ö†Ô∏è  AI overloaded (503). Waiting {wait_time}s (Attempt {retry_count + 1}/{RETRY_ATTEMPTS})")
                time.sleep(wait_time)
                return make_request(endpoint, method, data, headers, retry_count + 1)
            else:
                print(f"\n‚ùå AI service unavailable after {RETRY_ATTEMPTS} attempts")
                return None
        
        if response.status_code in [200, 201]:
            return response.json()
        else:
            print(f"\n‚ö†Ô∏è  API Error: {response.status_code}")
            return None
            
    except requests.exceptions.Timeout:
        print(f"\n‚ö†Ô∏è  Timeout")
        return None
    except Exception as e:
        print(f"\n‚ö†Ô∏è  Error: {e}")
        return None
    
def authenticate():
    """Authenticate admin"""
    print("üîê Authenticating...")
    
    result = make_request(
        "api/admin/login",
        method="POST",
        data=TEST_ADMIN
    )
    
    if result and result.get('success'):
        print(f"‚úÖ Authenticated as: {result.get('admin', {}).get('name')}")
        return result.get('token')
    else:
        print("‚ùå Authentication failed")
        return None

# ============================================================================
# TEST QUERIES - 50 DIVERSE TEST CASES
# ============================================================================

def get_test_queries():
    """
    50 diverse test queries covering all system capabilities
    Organized by complexity: Simple (15), Medium (18), Complex (17)
    """
    return [
        # ========================================================================
        # SIMPLE QUERIES (15) - Basic data retrieval
        # ========================================================================
        {
            "query": "How many patients visited today?",
            "category": "Basic Stats",
            "expected_keywords": ["patient", "today"]
        },
        {
            "query": "Show me today's appointments",
            "category": "Appointments",
            "expected_keywords": ["appointment", "today"]
        },
        {
            "query": "How many doctors are online?",
            "category": "Staff Info",
            "expected_keywords": ["doctor", "online", "consultant"]
        },
        {
            "query": "What is the busiest department?",
            "category": "Department",
            "expected_keywords": ["department", "busy"]
        },
        {
            "query": "Show current queue status",
            "category": "Queue",
            "expected_keywords": ["queue", "waiting"]
        },
        {
            "query": "What is today's patient count?",
            "category": "Basic Stats",
            "expected_keywords": ["patient", "count", "today"]
        },
        {
            "query": "How many lab tests today?",
            "category": "Lab Stats",
            "expected_keywords": ["lab", "test", "today"]
        },
        {
            "query": "What is the average wait time?",
            "category": "Wait Time",
            "expected_keywords": ["wait", "time", "average"]
        },
        {
            "query": "Show me active consultations",
            "category": "Consultations",
            "expected_keywords": ["consultation", "active"]
        },
        {
            "query": "Emergency department statistics",
            "category": "Department",
            "expected_keywords": ["emergency", "department"]
        },
        {
            "query": "List all available doctors",
            "category": "Staff Info",
            "expected_keywords": ["doctor", "available"]
        },
        {
            "query": "How many patients are waiting?",
            "category": "Queue",
            "expected_keywords": ["patient", "waiting"]
        },
        {
            "query": "Show me completed appointments",
            "category": "Appointments",
            "expected_keywords": ["appointment", "completed"]
        },
        {
            "query": "What's the current occupancy rate?",
            "category": "Capacity",
            "expected_keywords": ["occupancy", "rate"]
        },
        {
            "query": "Show me no-show statistics",
            "category": "Appointments",
            "expected_keywords": ["no-show", "missed"]
        },
        
        # ========================================================================
        # MEDIUM QUERIES (18) - Trends and analysis
        # ========================================================================
        {
            "query": "Show me fever trends this week",
            "category": "Health Trends",
            "expected_keywords": ["fever", "trend", "week"]
        },
        {
            "query": "What are the top 5 diagnoses?",
            "category": "Diagnosis",
            "expected_keywords": ["diagnosis", "top", "common"]
        },
        {
            "query": "Show patient demographics",
            "category": "Demographics",
            "expected_keywords": ["demographic", "age", "patient"]
        },
        {
            "query": "Which symptoms are most common?",
            "category": "Symptoms",
            "expected_keywords": ["symptom", "common"]
        },
        {
            "query": "Monthly appointment patterns",
            "category": "Trends",
            "expected_keywords": ["appointment", "pattern", "month"]
        },
        {
            "query": "Show me surgical cases",
            "category": "Surgery",
            "expected_keywords": ["surgery", "surgical", "case"]
        },
        {
            "query": "Pediatric patient trends",
            "category": "Pediatrics",
            "expected_keywords": ["pediatric", "children", "trend"]
        },
        {
            "query": "Department utilization rates",
            "category": "Utilization",
            "expected_keywords": ["department", "utilization"]
        },
        {
            "query": "Show me lab test results summary",
            "category": "Lab Analysis",
            "expected_keywords": ["lab", "result", "summary"]
        },
        {
            "query": "Maternity ward statistics",
            "category": "Maternity",
            "expected_keywords": ["maternity", "ward"]
        },
        {
            "query": "Analyze patient satisfaction scores",
            "category": "Quality",
            "expected_keywords": ["satisfaction", "patient"]
        },
        {
            "query": "Show medication prescription trends",
            "category": "Pharmacy",
            "expected_keywords": ["medication", "prescription"]
        },
        {
            "query": "Outpatient vs inpatient comparison",
            "category": "Patient Types",
            "expected_keywords": ["outpatient", "inpatient"]
        },
        {
            "query": "Show referral patterns",
            "category": "Referrals",
            "expected_keywords": ["referral", "pattern"]
        },
        {
            "query": "Analyze readmission rates",
            "category": "Quality",
            "expected_keywords": ["readmission", "rate"]
        },
        {
            "query": "Show critical care statistics",
            "category": "ICU",
            "expected_keywords": ["critical", "care", "icu"]
        },
        {
            "query": "Weekend vs weekday patient volume",
            "category": "Temporal Analysis",
            "expected_keywords": ["weekend", "weekday"]
        },
        {
            "query": "Show insurance claim statistics",
            "category": "Billing",
            "expected_keywords": ["insurance", "claim"]
        },
        
        # ========================================================================
        # COMPLEX QUERIES (17) - Multi-dimensional analysis
        # ========================================================================
        {
            "query": "Compare pediatric vs adult patients",
            "category": "Comparison",
            "expected_keywords": ["pediatric", "adult", "compare"]
        },
        {
            "query": "Analyze patient flow patterns by hour",
            "category": "Flow Analysis",
            "expected_keywords": ["patient", "flow", "hour"]
        },
        {
            "query": "What departments need more resources?",
            "category": "Resource Analysis",
            "expected_keywords": ["department", "resource"]
        },
        {
            "query": "Compare this month to last month",
            "category": "Temporal Comparison",
            "expected_keywords": ["month", "compare"]
        },
        {
            "query": "Identify bottlenecks in patient processing",
            "category": "Process Analysis",
            "expected_keywords": ["bottleneck", "patient"]
        },
        {
            "query": "Generate monthly performance report",
            "category": "Reporting",
            "expected_keywords": ["performance", "report", "month"]
        },
        {
            "query": "Analyze seasonal health patterns",
            "category": "Seasonal Analysis",
            "expected_keywords": ["seasonal", "pattern"]
        },
        {
            "query": "Cross-reference symptoms with age groups",
            "category": "Correlation",
            "expected_keywords": ["symptom", "age"]
        },
        {
            "query": "Predict tomorrow's patient volume",
            "category": "Prediction",
            "expected_keywords": ["predict", "patient", "volume"]
        },
        {
            "query": "Optimize department scheduling",
            "category": "Optimization",
            "expected_keywords": ["optimize", "schedule", "department"]
        },
        {
            "query": "Identify high-risk patient groups",
            "category": "Risk Analysis",
            "expected_keywords": ["risk", "patient", "group"]
        },
        {
            "query": "Compare morning vs afternoon efficiency",
            "category": "Operational Analysis",
            "expected_keywords": ["morning", "afternoon", "efficiency"]
        },
        {
            "query": "Analyze cost per patient by department",
            "category": "Financial Analysis",
            "expected_keywords": ["cost", "patient", "department"]
        },
        {
            "query": "Show correlation between wait time and satisfaction",
            "category": "Quality Metrics",
            "expected_keywords": ["wait", "satisfaction", "correlation"]
        },
        {
            "query": "Predict staffing needs for next week",
            "category": "Workforce Planning",
            "expected_keywords": ["staff", "predict", "need"]
        },
        {
            "query": "Identify patients who need follow-up",
            "category": "Care Management",
            "expected_keywords": ["follow-up", "patient"]
        },
        {
            "query": "Compare outcomes across different doctors",
            "category": "Performance Analysis",
            "expected_keywords": ["outcome", "doctor", "compare"]
        },
    ]

# ============================================================================
# SIMPLIFIED EVALUATION
# ============================================================================

def evaluate_response(response, test_case):
    """
    SIMPLIFIED evaluation - no confusion matrix
    Just checks: Did it give a helpful response?
    """
    if response is None:
        return {
            'understood': False,
            'helpful': False,
            'relevant': False,
            'response_quality': 'Failed'
        }
    
    text = response.get('textResponse', '').lower()
    
    # Check 1: Did AI understand? (response length > 30 chars)
    understood = len(text) > 30
    
    # Check 2: Is it relevant? (contains expected keywords)
    expected_keywords = test_case.get('expected_keywords', [])
    relevant = any(keyword in text for keyword in expected_keywords)
    
    # Check 3: Is it helpful? (not a rejection)
    rejection_phrases = [
        'cannot provide', 'unable to', 'not available',
        'insufficient data', 'unclear request', 'invalid query'
    ]
    not_rejected = not any(phrase in text for phrase in rejection_phrases)
    helpful = understood and not_rejected
    
    # Overall quality
    if understood and relevant and helpful:
        quality = 'Excellent'
    elif understood and helpful:
        quality = 'Good'
    elif understood:
        quality = 'Poor'
    else:
        quality = 'Failed'
    
    return {
        'understood': understood,
        'helpful': helpful,
        'relevant': relevant,
        'response_quality': quality
    }

# ============================================================================
# MAIN TEST
# ============================================================================

def test_chatbot_performance(token):
    """
    Test chatbot performance with aggressive rate limiting
    """
    print_header("CHATBOT PERFORMANCE TESTING - 50 TEST CASES")
    
    headers = {"Authorization": f"Bearer {token}"}
    
    # Get hospital data for context
    print("üìä Fetching hospital data...")
    dashboard = make_request("api/admin/dashboard-stats", headers=headers)
    
    if not dashboard:
        print("‚ùå Cannot get hospital data")
        return None
    
    print(f"‚úÖ Hospital data loaded")
    
    # Get test queries
    queries = get_test_queries()
    total = len(queries)
    
    print(f"\nü§ñ Testing {total} queries with AGGRESSIVE rate limiting")
    print(f"‚è±Ô∏è  Estimated time: ~{(total * DELAY_BETWEEN_REQUESTS) / 60:.1f} minutes")
    print(f"üõ°Ô∏è  Rate limit: {MAX_REQUESTS_PER_MINUTE} requests/minute")
    print(f"‚è≥ Delay per request: {DELAY_BETWEEN_REQUESTS}s")
    print(f"üîÑ Retry attempts: {RETRY_ATTEMPTS}")
    print(f"\nüìã Test Distribution:")
    print(f"   ‚Ä¢ Simple queries: 15")
    print(f"   ‚Ä¢ Medium queries: 18")
    print(f"   ‚Ä¢ Complex queries: 17\n")
    
    input("Press ENTER to start testing (this will take a while)...")
    
    results = []
    response_times = []
    
    for idx, test_case in enumerate(queries, 1):
        print(f"\n[{idx}/{total}] {test_case['query'][:60]}...")
        
        # APPLY RATE LIMITING BEFORE REQUEST
        smart_rate_limit()
        
        # Make request
        start = time.time()
        
        ai_response = make_request(
            "api/admin/analyze-data",
            method="POST",
            data={
                "query": test_case['query'],
                "hospitalData": dashboard.get('stats', {})
            },
            headers=headers
        )
        
        response_time = (time.time() - start) * 1000
        response_times.append(response_time)
        
        # Evaluate response
        evaluation = evaluate_response(ai_response, test_case)
        
        # Print result
        if evaluation['response_quality'] == 'Excellent':
            print(f"‚úÖ Excellent ({response_time:.0f}ms)")
        elif evaluation['response_quality'] == 'Good':
            print(f"‚úÖ Good ({response_time:.0f}ms)")
        elif evaluation['response_quality'] == 'Poor':
            print(f"‚ö†Ô∏è  Poor ({response_time:.0f}ms)")
        else:
            print(f"‚ùå Failed ({response_time:.0f}ms)")
        
        # Store result
        results.append({
            'test_case': idx,
            'query': test_case['query'],
            'category': test_case['category'],
            'understood': evaluation['understood'],
            'helpful': evaluation['helpful'],
            'relevant': evaluation['relevant'],
            'response_quality': evaluation['response_quality'],
            'response_time_ms': response_time,
            'under_5s': response_time <= 5000
        })
    
    # Calculate metrics
    df = pd.DataFrame(results)
    
    helpful_count = df['helpful'].sum()
    understood_count = df['understood'].sum()
    under_5s_count = df['under_5s'].sum()
    
    qra = (helpful_count / total * 100)
    nlur = (understood_count / total * 100)
    avg_time = np.mean(response_times)
    time_compliance = (under_5s_count / total * 100)
    
    # Print results
    print_header("PERFORMANCE TEST RESULTS (50 TEST CASES)")
    
    print(f"Total Queries: {total}")
    print(f"Understood: {understood_count}")
    print(f"Helpful Responses: {helpful_count}")
    print(f"Under 5 seconds: {under_5s_count}")
    
    print(f"\nüìä QUERY RESPONSE ACCURACY (QRA):")
    print(f"   Formula: (Helpful Responses / Total) √ó 100")
    print(f"   Result: {qra:.2f}%")
    print(f"   Target: ‚â•85%")
    print(f"   Status: {'‚úÖ PASS' if qra >= 85 else '‚ùå FAIL'}")
    
    print(f"\nüìä NATURAL LANGUAGE UNDERSTANDING (NLUR):")
    print(f"   Formula: (Understood / Total) √ó 100")
    print(f"   Result: {nlur:.2f}%")
    print(f"   Target: ‚â•90%")
    print(f"   Status: {'‚úÖ PASS' if nlur >= 90 else '‚ùå FAIL'}")
    
    print(f"\n‚è±Ô∏è  RESPONSE TIME:")
    print(f"   Average: {avg_time:.2f}ms")
    print(f"   Compliance: {time_compliance:.2f}%")
    print(f"   Target: ‚â§5000ms")
    print(f"   Status: {'‚úÖ PASS' if avg_time <= 5000 else '‚ùå FAIL'}")
    
    # Export results
    df.to_csv(f"{OUTPUT_DIR}/performance_results_50cases.csv", index=False)
    
    # Summary by category
    category_summary = df.groupby('category').agg({
        'helpful': 'mean',
        'understood': 'mean',
        'response_time_ms': 'mean'
    }).reset_index()
    category_summary.columns = ['Category', 'Helpful_Rate', 'Understanding_Rate', 'Avg_Response_Time']
    category_summary['Helpful_Rate'] *= 100
    category_summary['Understanding_Rate'] *= 100
    category_summary.to_csv(f"{OUTPUT_DIR}/category_summary_50cases.csv", index=False)
    
    # Complexity breakdown
    print(f"\nüìä PERFORMANCE BY COMPLEXITY:")
    complexity_map = {
        'Basic Stats': 'Simple', 'Appointments': 'Simple', 'Staff Info': 'Simple',
        'Department': 'Simple', 'Queue': 'Simple', 'Lab Stats': 'Simple',
        'Wait Time': 'Simple', 'Consultations': 'Simple', 'Capacity': 'Simple',
        'Health Trends': 'Medium', 'Diagnosis': 'Medium', 'Demographics': 'Medium',
        'Symptoms': 'Medium', 'Trends': 'Medium', 'Surgery': 'Medium',
        'Pediatrics': 'Medium', 'Utilization': 'Medium', 'Lab Analysis': 'Medium',
        'Maternity': 'Medium', 'Quality': 'Medium', 'Pharmacy': 'Medium',
        'Patient Types': 'Medium', 'Referrals': 'Medium', 'ICU': 'Medium',
        'Temporal Analysis': 'Medium', 'Billing': 'Medium',
        'Comparison': 'Complex', 'Flow Analysis': 'Complex', 'Resource Analysis': 'Complex',
        'Temporal Comparison': 'Complex', 'Process Analysis': 'Complex', 'Reporting': 'Complex',
        'Seasonal Analysis': 'Complex', 'Correlation': 'Complex', 'Prediction': 'Complex',
        'Optimization': 'Complex', 'Risk Analysis': 'Complex', 'Operational Analysis': 'Complex',
        'Financial Analysis': 'Complex', 'Quality Metrics': 'Complex', 'Workforce Planning': 'Complex',
        'Care Management': 'Complex', 'Performance Analysis': 'Complex'
    }
    df['complexity'] = df['category'].map(complexity_map)
    
    complexity_summary = df.groupby('complexity').agg({
        'helpful': ['sum', 'count', 'mean'],
        'response_time_ms': 'mean'
    }).round(2)
    
    for complexity in ['Simple', 'Medium', 'Complex']:
        if complexity in complexity_summary.index:
            total = complexity_summary.loc[complexity, ('helpful', 'count')]
            helpful = complexity_summary.loc[complexity, ('helpful', 'sum')]
            rate = complexity_summary.loc[complexity, ('helpful', 'mean')] * 100
            avg_time = complexity_summary.loc[complexity, ('response_time_ms', 'mean')]
            print(f"   {complexity:8s}: {helpful:.0f}/{total:.0f} helpful ({rate:.1f}%) | Avg: {avg_time:.0f}ms")
    
    # Save summary
    summary = {
        'test_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total_queries': int(total),  # ‚úÖ Convert to int
        'qra': float(qra),  # ‚úÖ Convert to float
        'nlur': float(nlur),
        'avg_response_time_ms': float(avg_time),
        'time_compliance': float(time_compliance),
        'status': 'PASS' if (qra >= 85 and nlur >= 90 and avg_time <= 5000) else 'FAIL'
    }
    
    with open(f"{OUTPUT_DIR}/summary_50cases.json", 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\n‚úÖ Results saved to: {OUTPUT_DIR}/")
    
    return summary

# ============================================================================
# MAIN EXECUTION
# ============================================================================

if __name__ == "__main__":
    print_header("CLICARE - CHATBOT PERFORMANCE TESTING")
    print("üéØ Tests: Response Quality, Speed, Understanding")
    print("üõ°Ô∏è  WITH AGGRESSIVE RATE LIMITING")
    print(f"üìä Test Cases: 50 (15 Simple + 18 Medium + 17 Complex)")
    print(f"\n‚ö†Ô∏è  This will take ~{(len(get_test_queries()) * DELAY_BETWEEN_REQUESTS) / 60:.1f} minutes")
    print("‚ö†Ô∏è  DO NOT interrupt the test - it's designed to prevent rate limits")
    
    create_output_dir()
    
    # Authenticate
    token = authenticate()
    if not token:
        print("\n‚ùå Cannot proceed without authentication")
        exit(1)
    
    # Run test
    try:
        result = test_chatbot_performance(token)
        
        if result:
            print_header("TEST COMPLETED")
            print(f"‚úÖ Overall Status: {result['status']}")
            print(f"üìÅ Results: {OUTPUT_DIR}/")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Test interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()